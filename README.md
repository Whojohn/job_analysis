# job_analysis
职位分析_拉勾
中文说明，流程及效果图
http://www.jianshu.com/p/7c8e2b34a649
所用技术
seleium requests jieba mysql pandas
2017.7.27.16.18更新（——@——吐槽一下，丢失了部分数据可恨，竟然没点保存） 提供一下几种分类方法：
    SGD,K-MEANS,NAVIE BAYES（放在ml文件夹中）
    其中sgd,navie bayes达到80%正确率,k-means40%.可能是不会调整k-means。
建模方法
    分词（预处理），tf-idf（数据转换），navie bayes。
存在问题：
    1.由于是短文本，而其是针对条目这种短文本，数据来源中，数据分布也不均匀，数据条目划分也不清除（可能不合理，毕竟一个人做，
下一步可能会找到一个行业条目分布之类的东西增加条目分类准确率，也减少个人工作量）。后序可能会引入cnn无监督分类（理想情况
下，让cnn自己划分类别，尽可能的细分，然后人工合并？？？一种想法）。
    2.技术是为了生产力，现实意义，花费4天解决分词这个问题，无用功做的比较多，这个项目的初衷是为了数据分析，现在有点偏离
轨道，下一步会详细分析（尝试记录各大城市的数据1分析职位分布（烂大街），通过热点画图，计算出公司群落，像北京互联网公司分
布是有规律的，为租房子提供决策帮助（我的实习+！+）。2通过统计学校，学生数量（数学专业，cs专业），培训机构（开设条目包含
课程的数量），推算出大概我们每一年需要跟多少人竞争（这一条挖的坑太大，只能按照很模糊预测。）。3分析条目在某个城市的前途
（发展是否有前途（什么公司？公司合作者？公司营业额？）未来回到家面临怎样情况？（像我这种在外地读书，以后回去的孩子提供决策
））。
好了，先填坑，再挖坑。

