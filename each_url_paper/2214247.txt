大数据 敏捷管理 开放式办公环境 团队活动
岗位职责：
1.深入研究Spark、Hadoop及其他大数据处理技术；
2.执行大数据平台研发计划；
3.处理现行产品平台中的问题。
 
岗位要求：
1.1年以上Spark、Hadoop项目相关工作经验；
2.了解大数据生态环境中的多项技术：HDFS/ElasticSearch等；
3.了解脚本编程(Shell / Python / Perl其中一种）；
4.良好的文档习惯、标准化的代码编写习惯；
5.良好的需求理解能力、测试习惯、学习和总结的能力。