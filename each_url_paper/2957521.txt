上市公司 免费午餐 加班补贴 六险一金
岗位职责：
1、基于Spark、hadoop等构建数据分析平台，进行设计、开发分布式计算业务；
2、关注业界大数据动态和发展方向，并能够独立研究；
3、辅助管理Spark、hadoop集群运行，稳定提供平台服务；
4、完成与工作相关的技术文档编写工作。
任职资格：
1、本科及以上学历，3年以上编程经验，熟悉Spark、hadoop研发、熟悉大数据集群的搭建、管理及优化；
2、熟悉hdfs/hbase/hive/spark/mapreduce/pig/mahout/impala，有丰富的分布式编程经验；
3、熟悉java研发，有实际编程经验；
4、熟练使用sql；
5、熟练掌握linux操作系统，熟悉shell等脚本编程；
6、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；
7、熟悉Lambda架构者优先考虑