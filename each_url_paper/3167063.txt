企业氛围佳,团队规模大,牛人达人多,专业培训多
注：工作地广州
岗位职责：
1、参与大数据智能平台、智能创新系统的等技术研发工作； 
2、参与基于Hadoop、Spark等大数据分析平台搭建，并进行设计、开发分布式计算业务； 
3、针对公司大数据业务，进行大数据处理与分析、挖掘应用的开发，涉及数据处理的不同环节包括：采集，存储，清洗及治理等； 
4、支持管理Hadoop、Spark集群运行、运维和监控，稳定提供平台服务； 
5、完成与工作相关的技术文档编写工作。 
岗位要求：
1、大专以上学历，计算机相关专业，2年以上开发经验，其中有1年以上大数据平台实际开发代码经验； 
2、熟悉Hadoop、Spark等大数据平台研发，熟悉大数据集群的搭建、管理及优化，熟悉大数据相关技术（Hdfs/Hbase/Hive/MapReduce /Pig/Mahout/Impala），有较好的分布式编程经验； 
3、熟练掌握Java等开发语言，熟练掌握Linux操作系统，至少熟练使用Shell、Python、Perl等脚本语言之一，熟悉R/Mathlab等统计脚本语言优先。 
4、熟练掌握SQL数据库语言HiveSQL/Mysql，有数据库编程经验、熟悉数据仓库的ETL的开发，有海量数据处理相关经验优先考虑。