五险一金,周末双休,生日会,下午茶
岗位职责:
1、大规模分布式互联网抓取系统的开发和维护；
2、文本分析与挖掘；
3、海量数据分析处理。
4、负责编写爬虫程序，爬取并清理外部数据，维护数据源抓取模版，监控第三方数据源的健康状况；
5、负责搭建、维护公司内部数据存储计算平台等基础设施，根据需求设计和实现底层通用性工具。
岗位要求：
1、精通SQLsever、Python；
2、3年以上互联网或企业级网络爬虫开发经验, 熟悉网络爬虫原理和策略；
3、熟悉种子、解析、下载、去重、提取、过滤、调度、DNS cache、异步处理等概念和过程，能够熟练配置解析模板；
4、熟悉Nutch/Heritrix/larbin/HtmlParser/HttpClient/Jsoup中的一种或多种开源技术；
5、熟练掌握主流应用服务器架构体系、数据库以及各种中间件技术，如tomcat、memcahced、Redis、HTTP、Ajax、Mysql、Kafuka等；
6、熟悉大规模系统的负载均衡、缓存、网络存储、网络安全、数据库高可用设计及性能评估机制。